# Helm charts

## Adding a helm chart
- It's getting annoying having to make a service and deployment each time, lets use helm
- https://registry.terraform.io/providers/hashicorp/helm/latest/docs
- We'll make an nginx helm chart to start, I'm also deleting the nginx deployment and service
```terraform
provider "helm" {
  kubernetes {
    host                   = digitalocean_kubernetes_cluster.cluster.endpoint
    token                  = digitalocean_kubernetes_cluster.cluster.kube_config[0].token
    cluster_ca_certificate = base64decode(
      digitalocean_kubernetes_cluster.cluster.kube_config[0].cluster_ca_certificate
    )
  }
}

resource "helm_release" "nginx_ingress" {
  name       = "nginx-ingress-controller"

  repository = "https://charts.bitnami.com/bitnami"
  chart      = "nginx-ingress-controller"

  set {
    name  = "service.type"
    value = "LoadBalancer"
  }
}
```
- It'll give the load balancer a public ip, you can go to that to check its working
- By installing that helm chart we've made a collection of kubernetes resources instead of having to list each of them
- There's 2 deployments, 2 services, and probably some other stuff
- You can also `helm ls` to see the helm charts currently installed

## Helming our services
- In frontend run `helm create frontend` to make the folder structure
- You can do `helm create --help` to understand the helm folder structure
- It makes a load files by default, we don't need most of them
- You can delete the charts folder
- We only need the `deployment.yaml` and `service.yaml` other stuff is interesting, but we don't need it
- I stripped out everything, trying to make it as minimal as possible
#### deployment.yaml
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.appName }}
  labels:
    app: {{ .Values.appName }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ .Values.appName }}
  template:
    metadata:
      labels:
        app: {{ .Values.appName }}
    spec:
      {{- if .Values.imagePullSecretsName }}
      imagePullSecrets:
        name: {{ .Values.imagePullSecretsName }}
      {{- end }}
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: {{ .Values.service.targetPort }}
              protocol: TCP
```
#### service.yaml
```yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ .Values.appName }}
  labels:
    app: {{ .Values.appName }}
spec:
  type: "LoadBalancer"
  ports:
    - port: {{ .Values.service.port }}
      targetPort: {{ .Values.service.targetPort }}
      protocol: TCP
      name: http
  selector:
    app: {{ .Values.appName }}
```
#### values.yaml
```yaml
replicaCount: 1

image:
  repository: nginx
  tag: latest

imagePullSecrets: []

service:
  port: 80
  targetPort: 3000

appName: frontend
```
- You can run `helm lint` to check it's valid
- Run `helm install frontend .` to add it to the cluster
- `helm uninstall` to remove it
- Add the helm chart in terraform
```terraform
resource "helm_release" "frontend" {
  name  = "frontend"
  chart = "${path.module}/../services/frontend/frontend"

  set {
    name  = "image.repository"
    value = "${digitalocean_container_registry.container_registry.endpoint}/frontend"
  }
  set {
    name  = "image.tag"
    value = "latest"
  }

  set {
    name = "imagePullSecretsName"
    value = kubernetes_secret.docker_credentials.metadata[0].name
  }

  set {
    name  = "service.port"
    value = "3000"
  }
  set {
    name  = "service.targetPort"
    value = "3000"
  }

  set {
      name  = "appName"
      value = "frontend"
  }
}
```
- Now do the same for the backend